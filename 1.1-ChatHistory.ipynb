{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Amar. As an aspiring GenAI engineer, you're likely excited about the vast potential of generative AI and its applications. Building a strong resume and portfolio can help you stand out in this competitive field. \\n\\nTo get started, can you tell me a bit more about your background and experience? What relevant skills or projects do you have under your belt? This will help me provide more tailored guidance on how to showcase your strengths and highlight your potential as a GenAI engineer.\\n\\nAlso, what are your goals? Are you looking to land a job at a top tech company, or perhaps pursue a research position in academia? Knowing your objectives will help me provide more focused advice on how to structure your resume and portfolio.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.3-70b-versatile\", groq_api_key=groq_api_key)\n",
    "output = model.invoke(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"Your help people with their resume and portfolio building \"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=\"Hey I am Amar, and I am an aspiring GenAI engineer\"\n",
    "        ),\n",
    "    ]   \n",
    ")\n",
    "\n",
    "output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is Amar. I'm glad we met earlier. How can I assist you today with your GenAI engineering journey?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "output = model.invoke(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"Hey I am Amar, and I am an aspiring GenAI engineer\"\n",
    "        ),\n",
    "        AIMessage(\n",
    "            content=\"That's great to hear, Amar! As an aspiring GenAI engineer, what specific areas are you looking to focus on in your resume and portfolio? Are there any particular skills or projects you'd like to highlight?\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=\"Do you remember my name\"\n",
    "        ),\n",
    "    ]   \n",
    ")\n",
    "\n",
    "output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langchain_community) (0.3.51)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langchain_community) (0.3.23)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langchain_community) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langchain_community) (3.11.16)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langchain_community) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langchain_community) (0.3.25)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.19.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (2.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (4.13.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (2.27.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/amar/anaconda3/envs/fastapi_env/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)-> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Amar.  As an aspiring GenAI engineer, you're likely interested in developing and working with highly advanced AI systems that can generate human-like text, images, and other forms of media. \\n\\nGenAI engineering is a rapidly evolving field, with new breakthroughs and innovations emerging regularly. What specific areas of GenAI are you most interested in or would like to explore further? Are you looking to work on natural language processing, computer vision, or perhaps multimodal models? \\n\\nAlso, what's your current level of experience with AI and programming? Are you looking for resources, guidance, or just want to discuss the latest developments in the field?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 135, 'prompt_tokens': 48, 'total_tokens': 183, 'completion_time': 0.490909091, 'prompt_time': 0.002764207, 'queue_time': 0.059328263, 'total_time': 0.493673298}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_72a5dc99ee', 'finish_reason': 'stop', 'logprobs': None}, id='run-8a30fa39-640f-4a51-b324-d26699eb51ae-0', usage_metadata={'input_tokens': 48, 'output_tokens': 135, 'total_tokens': 183})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"session_id\"}}\n",
    "\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(\n",
    "        content=\"Hey I am Amar, and I am an aspiring GenAI engineer\"\n",
    "    ),],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Amar. I'm glad we met earlier as an aspiring GenAI engineer. How can I assist you today, Amar?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 197, 'total_tokens': 225, 'completion_time': 0.113595162, 'prompt_time': 0.01488773, 'queue_time': 0.05922881299999999, 'total_time': 0.128482892}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_72a5dc99ee', 'finish_reason': 'stop', 'logprobs': None}, id='run-d8080c0f-f0f3-447b-bad4-1423ddc33914-0', usage_metadata={'input_tokens': 197, 'output_tokens': 28, 'total_tokens': 225})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(\n",
    "        content=\"Do you remember my name\"\n",
    "    ),],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You help answer questions with the best of your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")      \n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते अमर, मैं आपकी मदद करने में खुश हूँ। जेनेरल आर्टिफिशियल इंटेलिजेंस (GenAI) इंजीनियर बनने का आपका सपना बहुत ही रोमांचक है। यह क्षेत्र तेजी से विकसित हो रहा है और इसमें बहुत सारे अवसर हैं।\\n\\nआपको GenAI इंजीनियर बनने के लिए क्या कदम उठाने होंगे? क्या आपके पास कोई विशिष्ट योजना या लक्ष्य है? मैं आपको इस यात्रा में मदद करने के लिए तैयार हूँ।'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hey I am Amar, and I am an aspiring GenAI engineer\")],\"language\":\"Hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते अमर! आपका स्वागत है! मैं आपकी मदद करने के लिए तैयार हूँ। क्या हाल है? कुछ पूछना चाहते हैं या बस बात करना चाहते हैं?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat_id\"}}\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"Hey I am Amar\")],\"language\":\"Hindi\"},\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You help answer questions with the best of your ability in Hindi', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Do you remember my name', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Yes, your name is Amar. How can I help you today?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like to play cricket', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I'm glad to hear that! Cricket is a great sport. Do you play it often?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Yes, I play every weekend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"That's awesome! Playing every weekend sounds like a lot of fun. Do you play in a team or just with friends?\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=100,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=True,\n",
    "    start_on=\"human\"\n",
    "    )\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You help answer questions with the best of your ability in Hindi\"),\n",
    "    HumanMessage(content=\"Hey I am Amar, and I am an aspiring GenAI engineer\"),\n",
    "    AIMessage(content=\"Hello Amar! It's great to meet you. How can I assist you today?\"),\n",
    "    HumanMessage(content=\"Do you remember my name\"),\n",
    "    AIMessage(content=\"Yes, your name is Amar. How can I help you today?\"),\n",
    "    HumanMessage(content=\"I like to play cricket\"),\n",
    "    AIMessage(content=\"I'm glad to hear that! Cricket is a great sport. Do you play it often?\"),\n",
    "    HumanMessage(content=\"Yes, I play every weekend\"),\n",
    "    AIMessage(content=\"That's awesome! Playing every weekend sounds like a lot of fun. Do you play in a team or just with friends?\")\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'आप क्रिकेट खेलते हैं । (You play cricket.)'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "chain.invoke(\n",
    "    {\"messages\":messages + [HumanMessage(content=\"When sport do I play ?\")],\n",
    "     \"language\":\"English\"}\n",
    ").content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    "    )\n",
    "\n",
    "config={\"configurable\":{\"session_id\":\"chat_id2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Unfortunately, I don't have enough information to determine who you are. You could be anyone, and I don't have any context or clues to help me guess.\\n\\nIf you'd like to play a game or have some fun, you could give me some hints or clues about yourself, and I can try to guess who you are. Alternatively, you could ask me a question or start a conversation, and I can respond accordingly.\\n\\nSo, who are you? Want to give me a hint?\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"Who am I ?\")],\"language\":\"English\"},\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastapi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
